{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "042d20d7",
   "metadata": {},
   "source": [
    "## Naive Bayes Sentiment Polarity Classifier\n",
    "\n",
    "This notebook outlines our sentiment polarity model which takes movie reviews and predicts whether they are positive or negative based on the language used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d1bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7171e4a4",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "This function reads in the data and adds it to the training or test set while also labelling the data as positive or negative. \n",
    "\n",
    "This data contains 1000 positive and 1000 negative reviews. the data is split into 800 positive and 800 negative reviews for training and 100 postive and 100 negative reviews for testing. (90/10 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d325888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test():\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    neg_path = 'review_polarity/txt_sentoken/neg/'\n",
    "\n",
    "    #negative data\n",
    "    os.chdir(neg_path)\n",
    "    for file in os.listdir():\n",
    "        #find test data\n",
    "        if file[2]=='9':\n",
    "            with open(file, 'r') as f:\n",
    "                text = f.read()\n",
    "                text = text.lower()\n",
    "                text = re.sub(r'[^\\w\\s]','',text)\n",
    "                text = text.replace(\"\\n\", \"\")\n",
    "                test.append([file, text, 0])\n",
    "        #find training data\n",
    "        else:\n",
    "            with open(file, 'r') as f:\n",
    "                text = f.read()\n",
    "                text = text.lower()\n",
    "                text = re.sub(r'[^\\w\\s]','',text)\n",
    "                text = text.replace(\"\\n\", \"\")\n",
    "                train.append([file, text, 0])\n",
    "\n",
    "    #positive data\n",
    "    pos_path = '../../../review_polarity/txt_sentoken/pos/'\n",
    "    os.chdir(pos_path)\n",
    "    for file in os.listdir():\n",
    "        #find test data\n",
    "        if file[2]=='9':\n",
    "            with open(file, 'r') as f:\n",
    "                text = f.read()\n",
    "                text = text.lower()\n",
    "                text = re.sub(r'[^\\w\\s]','',text)\n",
    "                text = text.replace(\"\\n\", \"\")\n",
    "                test.append([file, text, 1])\n",
    "        #find training data\n",
    "        else:\n",
    "            with open(file, 'r') as f:\n",
    "                text = f.read()\n",
    "                text = text.lower()\n",
    "                text = re.sub(r'[^\\w\\s]','',text)\n",
    "                text = text.replace(\"\\n\", \"\")\n",
    "                train.append([file, text, 1])\n",
    "                \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73153224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_classes(train):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    #loop through each review\n",
    "    for review in train:\n",
    "        #find incidence where sentiment is positive\n",
    "        if review[2]==1:\n",
    "            pos+=1\n",
    "        else:\n",
    "            neg+=1\n",
    "            \n",
    "    return pos, neg, pos+neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee3677",
   "metadata": {},
   "source": [
    "## Create word frequencies dictionaries\n",
    "\n",
    "We create a positive, negative, and total word frequency dictionary from the training data which will then be used in the Naive Bayes function to predict word log likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40364db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(reviews):\n",
    "    pos_word_frequencies = {}\n",
    "    neg_word_frequencies = {}\n",
    "    total_vocab_frequencies = {}\n",
    "\n",
    "    for review in reviews:        \n",
    "        #find positive reviews\n",
    "        if review[2]==1:\n",
    "            words = review[1].strip().split()\n",
    "            for key in words:\n",
    "                if key in pos_word_frequencies:\n",
    "                    pos_word_frequencies[key] += 1\n",
    "                else:\n",
    "                    pos_word_frequencies[key] = 1\n",
    "\n",
    "                if key in total_vocab_frequencies:\n",
    "                    total_vocab_frequencies[key] += 1\n",
    "                else:\n",
    "                    total_vocab_frequencies[key] = 1\n",
    "                    \n",
    "        #negative reviews\n",
    "        else:\n",
    "            words = review[1].strip().split()\n",
    "            for key in words:\n",
    "                if key in neg_word_frequencies:\n",
    "                    neg_word_frequencies[key] += 1\n",
    "                else:\n",
    "                    neg_word_frequencies[key] = 1\n",
    "\n",
    "                if key in total_vocab_frequencies:\n",
    "                    total_vocab_frequencies[key] += 1\n",
    "                else:\n",
    "                    total_vocab_frequencies[key] = 1\n",
    "\n",
    "    return pos_word_frequencies, neg_word_frequencies, total_vocab_frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb51c6",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Naive Bayes is a probabilistic classifer which returns the most probable (maximum posterior probability) class c in a given document.\n",
    "\n",
    "$$\\hat{c} = \\underset{c\\in C}{\\operatorname{argmax}}P(c|d)$$\n",
    "\n",
    "In this case we are interested in whether the document belongs to the Positive (1) or Negative (0) class.\n",
    "\n",
    "Bayes rule allows us to infer the probability of a word in a document being positive or negative based on the following equation:\n",
    "\n",
    "$$P(x|y)= \\frac{P(y|x)P(x)}{P(y)}$$\n",
    "\n",
    "which for our model becomes \n",
    "\n",
    "$$P(c|d)= \\frac{P(d|c)P(c)}{P(d)}$$\n",
    "\n",
    "where $P(d|c)$ is our likelihood and $P(c)$ is our prior.\n",
    "\n",
    "Naive Bayes operates under the assumption that the probabilities are independant of one another and therefore may be multiplied by one another. In this model we shall use log space so our classes will be predicted using the final equation below:\n",
    "\n",
    "$$ c_{NB} = \\underset{c\\in C}{\\operatorname{argmax}}P(c)+\\underset{i\\in positions}\\sum{logP(w_{i}|c)} $$\n",
    "\n",
    "\n",
    "The prior is calculated as:\n",
    "\n",
    "$$\\hat{P}(c)= \\frac{N_{c}}{N_{doc}}$$\n",
    "\n",
    "We use Laplace smoothing or add one smoothing to give the following equation:\n",
    "\n",
    "$$\\hat{P}(w_{i}|c)=\\frac{count(w_{i},c)+1}{(\\sum_{w \\in V}count(w,c))+|V|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7efff822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(train, test):\n",
    "\n",
    "    #training phase\n",
    "    pos_loglikelihood = {}\n",
    "    neg_loglikelihood = {}\n",
    "    count_pos, count_neg, total_docs = count_classes(train)\n",
    "    prior_pos = math.log(count_pos/total_docs)\n",
    "    prior_neg = math.log(count_neg/total_docs)\n",
    "    pos_dict, neg_dict, full_vocab_dict = count_words(train)\n",
    "\n",
    "    #add positive log likelihoods\n",
    "    pos_sum_counts = sum(pos_dict.values())\n",
    "    for word in pos_dict:\n",
    "        pos_loglikelihood[word] = math.log((pos_dict[word]+1)/(pos_sum_counts+len(full_vocab_dict)))\n",
    "\n",
    "    neg_sum_counts = sum(neg_dict.values())\n",
    "    #add negative log likelihoods\n",
    "    for word in neg_dict:\n",
    "        neg_loglikelihood[word] = math.log((neg_dict[word]+1)/(neg_sum_counts+len(full_vocab_dict)))\n",
    "\n",
    "    #add likelihood for words in vocab but not in one of the dictionaries\n",
    "    pos_keys = pos_dict.keys()\n",
    "    neg_keys = neg_dict.keys()\n",
    "    all_vocab_keys = full_vocab_dict.keys()\n",
    "\n",
    "    #find words present in main vocab but not in positive vocab and vice versa\n",
    "    pos_diff = all_vocab_keys - pos_keys\n",
    "    neg_diff = all_vocab_keys - neg_keys\n",
    "    \n",
    "    for word in pos_diff:\n",
    "        pos_loglikelihood[word] = math.log(1/(pos_sum_counts + len(full_vocab_dict)))\n",
    "             \n",
    "    for word in neg_diff:\n",
    "        neg_loglikelihood[word] = math.log(1/(neg_sum_counts + len(full_vocab_dict)))\n",
    "\n",
    "    #testing phase\n",
    "    accurate_prediction = 0\n",
    "    for review in test:\n",
    "        \n",
    "        pos_prob, neg_prob = 0, 0\n",
    "        pos_prob+= prior_pos\n",
    "        neg_prob+= prior_neg\n",
    "        words = review[1].strip().split()\n",
    "        for word in words:\n",
    "            if word in full_vocab_dict:\n",
    "                if word in pos_loglikelihood:\n",
    "                    pos_prob += pos_loglikelihood[word]\n",
    "                if word in neg_loglikelihood:\n",
    "                    neg_prob += neg_loglikelihood[word]\n",
    "\n",
    "        if pos_prob > neg_prob:\n",
    "            review.append(1)\n",
    "        else:\n",
    "            review.append(0)\n",
    "            \n",
    "        if review[2]==review[3]:\n",
    "            accurate_prediction+=1\n",
    "        \n",
    "    total_test_reviews = len(test)\n",
    "    accuracy = 'The Accuracy of the Naive Bayes sentiment polarity classifier is: ' + str((accurate_prediction / total_test_reviews)*100) + '%'\n",
    "\n",
    "    return accuracy, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc37dd2",
   "metadata": {},
   "source": [
    "## Sample results\n",
    "\n",
    "To review the performance of the classifer, we want to be able to sample the positive and negative results. The function below allows us to select 5 correct predictions and 5 incorrect predictions at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb6618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_results(predictions):\n",
    "    correct = []\n",
    "    incorrect = []\n",
    "    for row in predictions:\n",
    "        if row[2]==row[3]:\n",
    "            correct.append(row)\n",
    "        else:\n",
    "            incorrect.append(row)\n",
    "\n",
    "    correct_5 = random.sample(correct, 5)\n",
    "    incorrect_5 = random.sample(incorrect, 5)\n",
    "\n",
    "    return correct_5, incorrect_5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a98e6c",
   "metadata": {},
   "source": [
    "## Output of reviews and predictions for investigation\n",
    "\n",
    "This function below allows us to output the selected correctly and incorrectly classified reviews and formats them into the `ANALYSIS.md` file for investigation and to add further comments on why the prediction was correct/incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a91b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_samples(good, bad):\n",
    "        with open('../../../ANALYSIS.md', 'w') as f:\n",
    "            f.write('# Analysis of Sentiment Classifier \\n \\n')\n",
    "\n",
    "            f.write('## Correct Predictions: \\n \\n')\n",
    "            for review in good:\n",
    "                sentiment = 'Positive' if review[2] == 1 else 'Negative'\n",
    "                predicted = 'Positive' if review[3] == 1 else 'Negative'\n",
    "                f.write('### Filename: '+ review[0] + '\\n### Sentiment: '+ sentiment + '\\n### Predicted: '+predicted +' \\n \\n### Review: \\n')\n",
    "                f.write(review[1] + '\\n \\n')\n",
    "\n",
    "            f.write('\\n \\n \\n \\n \\n ## Incorrect Predictions: \\n \\n')\n",
    "            for review in bad:\n",
    "                sentiment = 'Positive' if review[2] == 1 else 'Negative'\n",
    "                predicted = 'Positive' if review[3] == 1 else 'Negative'\n",
    "                f.write('### Filename: '+ review[0] + '\\n### Sentiment: '+ sentiment+ '\\n### Predicted: '+predicted +' \\n \\n### Review: \\n') \n",
    "                f.write(review[1] + '\\n \\n')\n",
    "\n",
    "            f.write('## Conclusion')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907354b9",
   "metadata": {},
   "source": [
    "## Running the code\n",
    "\n",
    "The below cell calls the functions to do the following:\n",
    "\n",
    "- Train the model on the training data\n",
    "- Test the model predictions on the test data\n",
    "- Output the Accuracy of the model\n",
    "- Output a selected sample of predictions to `ANALYSIS.md` for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db4dd635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the Naive Bayes sentiment polarity classifier is: 83.5%\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test()\n",
    "results, predictions = naive_bayes(train, test)\n",
    "print(results)\n",
    "correct, incorrect = sample_results(predictions)\n",
    "output_samples(correct, incorrect)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
